{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472dd99a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flairNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for flair from https://files.pythonhosted.org/packages/f0/e3/a1b157afb740defde094949443a088f5d0b3af46be6344fef71d589cb0e1/flair-0.13.0-py3-none-any.whl.metadata\n",
      "  Using cached flair-0.13.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Obtaining dependency information for boto3>=1.20.27 from https://files.pythonhosted.org/packages/4c/84/abe01852ed53db1be164ed857a833466c6e79e63d3fffeb1e456920d615d/boto3-1.29.3-py3-none-any.whl.metadata\n",
      "  Using cached boto3-1.29.3-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting bpemb>=0.3.2 (from flair)\n",
      "  Using cached bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
      "Collecting conllu>=4.0 (from flair)\n",
      "  Obtaining dependency information for conllu>=4.0 from https://files.pythonhosted.org/packages/ce/3f/70a1dc5bc536755ec082b806594598a10cfffaf0de978f51d4e0e4fdfa47/conllu-4.5.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair)\n",
      "  Obtaining dependency information for deprecated>=1.2.13 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Using cached gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Collecting gensim>=4.2.0 (from flair)\n",
      "  Using cached gensim-4.3.2.tar.gz (23.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting huggingface-hub>=0.10.0 (from flair)\n",
      "  Obtaining dependency information for huggingface-hub>=0.10.0 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting janome>=0.4.2 (from flair)\n",
      "  Obtaining dependency information for janome>=0.4.2 from https://files.pythonhosted.org/packages/73/7d/70f4069f4bbf0fca023e82a1fbbade6f5216365d4fe259fee1950723eca5/Janome-0.5.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached Janome-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langdetect>=1.0.9 (from flair)\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting lxml>=4.8.0 (from flair)\n",
      "  Obtaining dependency information for lxml>=4.8.0 from https://files.pythonhosted.org/packages/77/e5/1f23e56678244258483521872507d64130cac9466902aca3f3141b8fb06b/lxml-4.9.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached lxml-4.9.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair) (3.8.1)\n",
      "Collecting more-itertools>=8.13.0 (from flair)\n",
      "  Obtaining dependency information for more-itertools>=8.13.0 from https://files.pythonhosted.org/packages/5a/cb/6dce742ea14e47d6f565589e859ad225f2a5de576d7696e0623b784e226b/more_itertools-10.1.0-py3-none-any.whl.metadata\n",
      "  Using cached more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Using cached mpld3-0.5.9-py3-none-any.whl (201 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Using cached pptree-3.1.tar.gz (3.0 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from flair) (2.8.2)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Using cached pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting regex>=2022.1.18 (from flair)\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/d3/10/6f2d5f8635d7714ad97ce6ade7a643358c4f3e45cde4ed12b7150734a8f3/regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting scikit-learn>=1.0.2 (from flair)\n",
      "  Obtaining dependency information for scikit-learn>=1.0.2 from https://files.pythonhosted.org/packages/fe/6b/db949ed5ac367987b1f250f070f340b7715d22f0c9c965bdf07de6ca75a3/scikit_learn-1.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Using cached segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Using cached sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tabulate>=0.8.10 (from flair)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "INFO: pip is looking at multiple versions of flair to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting flair\n",
      "  Using cached flair-0.12.2-py3-none-any.whl (373 kB)\n",
      "  Using cached flair-0.12.1-py3-none-any.whl (374 kB)\n",
      "  Using cached flair-0.12-py3-none-any.whl (374 kB)\n",
      "  Using cached flair-0.11.3-py3-none-any.whl (401 kB)\n",
      "  Using cached flair-0.11.2-py3-none-any.whl (402 kB)\n",
      "  Using cached flair-0.11.1-py3-none-any.whl (401 kB)\n",
      "  Using cached flair-0.11-py3-none-any.whl (400 kB)\n",
      "INFO: pip is still looking at multiple versions of flair to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached flair-0.10-py3-none-any.whl (322 kB)\n",
      "  Using cached flair-0.9-py3-none-any.whl (319 kB)\n",
      "  Using cached flair-0.8.0.post1-py3-none-any.whl (284 kB)\n",
      "  Using cached flair-0.8-py3-none-any.whl (277 kB)\n",
      "  Using cached flair-0.7-py3-none-any.whl (448 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached flair-0.6.1.post1-py3-none-any.whl (337 kB)\n",
      "  Using cached flair-0.6.1-py3-none-any.whl (331 kB)\n",
      "  Using cached flair-0.6.0.post1-py3-none-any.whl (241 kB)\n",
      "  Using cached flair-0.6-py3-none-any.whl (241 kB)\n",
      "  Using cached flair-0.5.1-py3-none-any.whl (201 kB)\n",
      "  Using cached flair-0.5-py3-none-any.whl (334 kB)\n",
      "  Using cached flair-0.4.5-py3-none-any.whl (136 kB)\n",
      "  Using cached flair-0.4.4-py3-none-any.whl (193 kB)\n",
      "  Using cached flair-0.4.3-py3-none-any.whl (180 kB)\n",
      "  Using cached flair-0.4.2-py3-none-any.whl (136 kB)\n",
      "  Using cached flair-0.4.1.tar.gz (78 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached flair-0.4.0.tar.gz (70 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached flair-0.3.2.tar.gz (57 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached flair-0.3.1.tar.gz (55 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached flair-0.3.0.tar.gz (55 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached flair-0.2.1.tar.gz (40 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [23 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\pc\\AppData\\Local\\Temp\\pip-build-env-qkbjmnzc\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 355, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\pc\\AppData\\Local\\Temp\\pip-build-env-qkbjmnzc\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\pc\\AppData\\Local\\Temp\\pip-build-env-qkbjmnzc\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 507, in run_setup\n",
      "          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\pc\\AppData\\Local\\Temp\\pip-build-env-qkbjmnzc\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 341, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 7, in <module>\n",
      "        File \"c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "          return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 6173: character maps to <undefined>\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d83af97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flair'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pc\\Downloads\\Telegram Desktop\\final2.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pc/Downloads/Telegram%20Desktop/final2.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflair\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m ClassificationCorpus\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pc/Downloads/Telegram%20Desktop/final2.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflair\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Corpus\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pc/Downloads/Telegram%20Desktop/final2.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflair\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m \u001b[39mimport\u001b[39;00m WordEmbeddings, DocumentRNNEmbeddings, FlairEmbeddings\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flair'"
     ]
    }
   ],
   "source": [
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.data import Corpus\n",
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings, FlairEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# Chargement du corpus\n",
    "data_folder = '.'  # \n",
    "\n",
    "\n",
    "Corpus = ClassificationCorpus(data_folder=data_folder, test_file='train.csv', dev_file='val.csv', train_file='test.csv')\n",
    "\n",
    "# Création du dictionnaire d'étiquettes\n",
    "label_dict = corpus.make_label_dictionary(label_type='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a62b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5552bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création du dictionnaire d'étiquettes\n",
    "label_dict = corpus.make_label_dictionary(label_type='class')\n",
    "\n",
    "# Définition des embeddings\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast')]\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "\n",
    "# Création du classificateur de texte\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type='class')\n",
    "\n",
    "# Initialisation du formateur de modèle\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90bdd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 20:54:20,315 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,325 Model: \"TextClassifier(\n",
      "  (embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings(\n",
      "        'glove'\n",
      "        (embedding): Embedding(400001, 100)\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=1124, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2023-11-11 20:54:20,325 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,328 Corpus: 13811 train + 13803 dev + 31567 test sentences\n",
      "2023-11-11 20:54:20,328 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,328 Train:  13811 sentences\n",
      "2023-11-11 20:54:20,328         (train_with_dev=False, train_with_test=False)\n",
      "2023-11-11 20:54:20,328 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,336 Training Params:\n",
      "2023-11-11 20:54:20,339  - learning_rate: \"0.01\" \n",
      "2023-11-11 20:54:20,348  - mini_batch_size: \"300\"\n",
      "2023-11-11 20:54:20,348  - max_epochs: \"3\"\n",
      "2023-11-11 20:54:20,348  - shuffle: \"True\"\n",
      "2023-11-11 20:54:20,348 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,348 Plugins:\n",
      "2023-11-11 20:54:20,348  - AnnealOnPlateau | patience: '2', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
      "2023-11-11 20:54:20,348 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,356 Final evaluation on model from best epoch (best-model.pt)\n",
      "2023-11-11 20:54:20,356  - metric: \"('micro avg', 'f1-score')\"\n",
      "2023-11-11 20:54:20,356 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,362 Computation:\n",
      "2023-11-11 20:54:20,364  - compute on device: cpu\n",
      "2023-11-11 20:54:20,364  - embedding storage: cpu\n",
      "2023-11-11 20:54:20,364 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,364 Model training base path: \"saves\"\n",
      "2023-11-11 20:54:20,372 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 20:54:20,372 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\anac\\lib\\site-packages\\flair\\trainers\\trainer.py:84: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\anaconda3\\anac\\lib\\site-packages\\torch\\autocast_mode.py:156: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 20:55:59,563 epoch 1 - iter 4/47 - loss 0.70597697 - time (sec): 99.19 - samples/sec: 12.10 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 20:57:34,308 epoch 1 - iter 8/47 - loss 0.70026981 - time (sec): 193.94 - samples/sec: 12.38 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 20:59:10,286 epoch 1 - iter 12/47 - loss 0.69763287 - time (sec): 289.91 - samples/sec: 12.42 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:00:48,459 epoch 1 - iter 16/47 - loss 0.69505566 - time (sec): 388.09 - samples/sec: 12.37 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:02:24,781 epoch 1 - iter 20/47 - loss 0.69292014 - time (sec): 484.41 - samples/sec: 12.39 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:04:07,388 epoch 1 - iter 24/47 - loss 0.69031675 - time (sec): 587.02 - samples/sec: 12.27 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:05:43,876 epoch 1 - iter 28/47 - loss 0.68716006 - time (sec): 683.50 - samples/sec: 12.29 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:07:00,286 epoch 1 - iter 32/47 - loss 0.68588865 - time (sec): 759.91 - samples/sec: 12.63 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:08:16,332 epoch 1 - iter 36/47 - loss 0.68430592 - time (sec): 835.96 - samples/sec: 12.92 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:09:28,793 epoch 1 - iter 40/47 - loss 0.68241876 - time (sec): 908.42 - samples/sec: 13.21 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:10:40,976 epoch 1 - iter 44/47 - loss 0.68097878 - time (sec): 980.60 - samples/sec: 13.46 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:11:19,513 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 21:11:19,513 EPOCH 1 done: loss 0.6800 - lr: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 216/216 [09:08<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 21:20:28,479 DEV : loss 0.6836186647415161 - f1-score (micro avg)  0.5538\n",
      "2023-11-11 21:20:34,338  - 0 epochs without improvement\n",
      "2023-11-11 21:20:34,354 saving best model\n",
      "2023-11-11 21:20:35,479 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\anac\\lib\\site-packages\\torch\\autocast_mode.py:156: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 21:21:49,219 epoch 2 - iter 4/47 - loss 0.67914675 - time (sec): 73.73 - samples/sec: 16.28 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:23:11,162 epoch 2 - iter 8/47 - loss 0.66859947 - time (sec): 155.67 - samples/sec: 15.42 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:24:48,388 epoch 2 - iter 12/47 - loss 0.66577139 - time (sec): 252.89 - samples/sec: 14.24 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:26:00,275 epoch 2 - iter 16/47 - loss 0.66210956 - time (sec): 324.78 - samples/sec: 14.78 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:27:14,194 epoch 2 - iter 20/47 - loss 0.66038180 - time (sec): 398.70 - samples/sec: 15.05 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:28:25,227 epoch 2 - iter 24/47 - loss 0.65917290 - time (sec): 469.73 - samples/sec: 15.33 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:29:40,167 epoch 2 - iter 28/47 - loss 0.66013261 - time (sec): 544.67 - samples/sec: 15.42 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:30:55,100 epoch 2 - iter 32/47 - loss 0.66063071 - time (sec): 619.61 - samples/sec: 15.49 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:32:09,509 epoch 2 - iter 36/47 - loss 0.66030415 - time (sec): 694.01 - samples/sec: 15.56 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:33:26,642 epoch 2 - iter 40/47 - loss 0.66029812 - time (sec): 771.15 - samples/sec: 15.56 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:34:42,215 epoch 2 - iter 44/47 - loss 0.65877194 - time (sec): 846.72 - samples/sec: 15.59 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:35:21,027 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 21:35:21,043 EPOCH 2 done: loss 0.6583 - lr: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 216/216 [08:54<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 21:44:15,628 DEV : loss 0.6337406039237976 - f1-score (micro avg)  0.6544\n",
      "2023-11-11 21:44:21,393  - 0 epochs without improvement\n",
      "2023-11-11 21:44:21,393 saving best model\n",
      "2023-11-11 21:44:22,627 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\anac\\lib\\site-packages\\torch\\autocast_mode.py:156: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 21:45:38,245 epoch 3 - iter 4/47 - loss 0.63537726 - time (sec): 75.62 - samples/sec: 15.87 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:46:53,693 epoch 3 - iter 8/47 - loss 0.65217782 - time (sec): 151.07 - samples/sec: 15.89 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:48:08,743 epoch 3 - iter 12/47 - loss 0.65287000 - time (sec): 226.12 - samples/sec: 15.92 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:49:26,356 epoch 3 - iter 16/47 - loss 0.65572439 - time (sec): 303.73 - samples/sec: 15.80 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:50:42,694 epoch 3 - iter 20/47 - loss 0.65249071 - time (sec): 380.07 - samples/sec: 15.79 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:51:59,321 epoch 3 - iter 24/47 - loss 0.64950898 - time (sec): 456.69 - samples/sec: 15.77 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:53:17,147 epoch 3 - iter 28/47 - loss 0.64792477 - time (sec): 534.52 - samples/sec: 15.72 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:54:34,976 epoch 3 - iter 32/47 - loss 0.64866731 - time (sec): 612.35 - samples/sec: 15.68 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:55:50,510 epoch 3 - iter 36/47 - loss 0.64948366 - time (sec): 687.88 - samples/sec: 15.70 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:57:08,099 epoch 3 - iter 40/47 - loss 0.64843587 - time (sec): 765.47 - samples/sec: 15.68 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:58:26,178 epoch 3 - iter 44/47 - loss 0.64733964 - time (sec): 843.55 - samples/sec: 15.65 - lr: 0.010000 - momentum: 0.000000\n",
      "2023-11-11 21:59:05,363 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 21:59:05,363 EPOCH 3 done: loss 0.6476 - lr: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 216/216 [09:06<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 22:08:12,493 DEV : loss 0.6246241331100464 - f1-score (micro avg)  0.6568\n",
      "2023-11-11 22:08:18,742  - 0 epochs without improvement\n",
      "2023-11-11 22:08:18,758 saving best model\n",
      "2023-11-11 22:08:21,117 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-11 22:08:21,117 Loading model from best epoch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 494/494 [20:12<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 22:28:35,397 \n",
      "Results:\n",
      "- F-score (micro) 0.6557\n",
      "- F-score (macro) 0.6533\n",
      "- Accuracy 0.6557\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6330    0.7396    0.6821     15768\n",
      "           1     0.6876    0.5720    0.6245     15799\n",
      "\n",
      "    accuracy                         0.6557     31567\n",
      "   macro avg     0.6603    0.6558    0.6533     31567\n",
      "weighted avg     0.6603    0.6557    0.6533     31567\n",
      "\n",
      "2023-11-11 22:28:35,397 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6557164127094751}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train(\n",
    "    'saves',  # Répertoire où sauvegarder les modèles\n",
    "    learning_rate=0.01,                             # Taux d'apprentissage initial\n",
    "    mini_batch_size=300,                            # Taille des mini-lots pour l'entraînement\n",
    "    anneal_factor=0.5,                             # Facteur pour réduire le taux d'apprentissage en cas de stagnation\n",
    "    patience=2,                                    # Nombre d'époques sans amélioration avant de réduire le taux d'apprentissage\n",
    "    max_epochs=3,                                # Nombre maximal d'époques d'entraînement\n",
    "    embeddings_storage_mode='cpu'                 # Mode de stockage des embeddings ('cpu' pour utiliser le CPU)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447252d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "import string\n",
    "string.punctuation\n",
    "def suppression_ponctuation(text):\n",
    "    ponctuation=[char for char in text if char not in string.punctuation]\n",
    "    return ''.join(ponctuation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79743a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def suppression_ponctuation(text):\n",
    "    result = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7bd2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# définition des fonctions pour le prétraitement\n",
    "def clean2(text):\n",
    "    text = [char for char in text if char in allowed_chars]\n",
    "    return ''.join(text)\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #\n",
    "    text = re.sub(r'#','',text) #supprime '#'\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text) #supprime les liens\n",
    "    text = suppression_ponctuation(text)\n",
    "    text = clean2(text)\n",
    "    return text\n",
    "\n",
    "# pour importer la bibliothèque d'expression\n",
    "import re\n",
    "\n",
    "allowed_chars = ' AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz0123456789~`!@#$%^&*()-=_+[]{}|;:\",./<>?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdafe7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "positive_sentence = Sentence(clean('I love Python!'))\n",
    "negative_sentence = Sentence(clean('I don\\'t like Python'))\n",
    "\n",
    "classifier.predict(positive_sentence)\n",
    "classifier.predict(negative_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9fa419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentence[3]: \"I love Python\"'/'1' (0.6006)]\n",
      "['Sentence[4]: \"I dont like Python\"'/'1' (0.5495)]\n",
      "Sentence[3]: \"English is good\" → 1 (0.7237)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phrase=Sentence(clean(\"English is good\"))\n",
    "classifier.predict((phrase))\n",
    "classifier.predict(negative_sentence)\n",
    "\n",
    "print(positive_sentence.labels)\n",
    "print(negative_sentence.labels)\n",
    "print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c1ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_user_input():\n",
    "    # Demander à l'utilisateur de saisir une phrase\n",
    "    user_input = input(\"Veuillez saisir une phrase : \")\n",
    "    # Nettoyer la ponctuation de la phrase\n",
    "    cleaned_input = clean(user_input)\n",
    "    \n",
    "    # Créer une phrase Flair à partir de l'entrée utilisateur\n",
    "    user_sentence = Sentence(cleaned_input)\n",
    "    \n",
    "    # Faire la prédiction avec le modèle\n",
    "    classifier.predict(user_sentence)\n",
    "     # Afficher les résultats de la prédiction\n",
    "    print(\"Résultat de la prédiction :\")\n",
    "    for label in user_sentence.labels:\n",
    "        print(f\"Classe : {label.value} - Probabilité : {label.score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc11d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veuillez saisir une phrase : Tout s'est bien passé\n",
      "Résultat de la prédiction :\n",
      "Classe : 1 - Probabilité : 0.62\n"
     ]
    }
   ],
   "source": [
    "result=predict_user_input()\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
